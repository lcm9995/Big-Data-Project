{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66a85f3e",
   "metadata": {},
   "source": [
    "## Install Dependencies (if needed) ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cc3a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" !pip install statsmodel\n",
    "!pip install pyspark\n",
    "!pip install pandas\n",
    "!pip install plotly\n",
    "!pip install geopandas\n",
    "!pip install numpy\n",
    "!pip install sklearn \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814157a1",
   "metadata": {},
   "source": [
    "## Create Spark Session ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8864cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"NYC Taxi — Analysis Only\") \\\n",
    "    .config(\"spark.driver.memory\", \"6g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"50\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark session created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f05173",
   "metadata": {},
   "source": [
    "## Load Data from Parquet ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a4134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = spark.read.parquet(\"Cleaned_Parquet/combined/\")\n",
    "city_hourly = spark.read.parquet(\"Cleaned_Parquet/city_hourly/\")\n",
    "zone_hourly = spark.read.parquet(\"Cleaned_Parquet/zone_hourly/\")\n",
    "taxi_df = spark.read.parquet(\"Cleaned_Parquet/ taxi_clean/\")\n",
    "weather_df = spark.read.parquet(\"Cleaned_Parquet/weather_clean/\")\n",
    "print(\"Combined df schema\")\n",
    "combined_df.printSchema()\n",
    "print(\"City hourly schema\")\n",
    "city_hourly.printSchema()\n",
    "print(\"Zone hourly schema\")\n",
    "zone_hourly.printSchema()\n",
    "print(\"Weather schema\")\n",
    "weather_df.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19abc3a6",
   "metadata": {},
   "source": [
    "Load geojson data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40500122",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones_geo = gpd.read_file(\"taxi_zones.geojson\")  # contains Zone + LocationID\n",
    "print(zones_geo.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a4b763",
   "metadata": {},
   "source": [
    "## Question 1: How Does Hourly Taxi Demand Vary Throughout the Day? ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8003d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: How does hourly taxi demand vary throughout the day?\n",
    "demand_by_hour = city_hourly.groupBy('hour').agg(avg('trip_count').alias('avg_trips')).orderBy('hour')\n",
    "demand_by_hour.show(24)\n",
    "\n",
    "# Export\n",
    "demand_by_hour.coalesce(1).write.mode('overwrite').csv('outputs/demand_by_hour.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1896df54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Convert to pandas (24 rows — safe)\n",
    "df_hourly = demand_by_hour.toPandas()\n",
    "\n",
    "fig = px.line(\n",
    "    df_hourly,\n",
    "    x=\"hour\",\n",
    "    y=\"avg_trips\",\n",
    "    title=\"Average NYC Taxi Demand by Hour of Day\",\n",
    "    markers=True,\n",
    "    labels={\"hour\": \"Hour of Day (0–23)\", \"avg_trips\": \"Avg Trips per Hour\"},\n",
    "    template=\"plotly_dark\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(dtick=1),\n",
    "    title_font_size=20,\n",
    "    yaxis_title=\"Avg Trips\",\n",
    "    xaxis_title=\"Hour\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01f0484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from pyspark.sql import functions as F\n",
    "zone_demand = combined_df.groupBy(\"PULocationID\").agg(\n",
    "    F.count(\"*\").alias(\"total_trips\"),\n",
    "    F.avg(\"fare_amount\").alias(\"avg_fare\"),\n",
    "    F.avg(\"duration_min\").alias(\"avg_trip_duration\")\n",
    ")\n",
    "zone_pd = zone_demand.toPandas()\n",
    "zones_geo[\"location_id\"] = zones_geo[\"location_id\"].astype(int)\n",
    "zones_merged = zones_geo.merge(zone_pd, left_on=\"location_id\", right_on=\"PULocationID\", how=\"left\")\n",
    "zones_merged[\"total_trips\"] = zones_merged[\"total_trips\"].fillna(0)\n",
    "fig = px.choropleth_mapbox(\n",
    "    zones_merged,\n",
    "    geojson=zones_merged.geometry.__geo_interface__,\n",
    "    locations=zones_merged.index,\n",
    "    color=\"total_trips\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    center={\"lat\": 40.75, \"lon\": -73.97},\n",
    "    zoom=9.8,\n",
    "    opacity=0.7,\n",
    "    color_continuous_scale=\"YlOrRd\",\n",
    "    title=\"NYC Taxi Demand by Pickup Zone\",\n",
    ")\n",
    "\n",
    "fig.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d78ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Extract date only\n",
    "daily_zone = combined_df.withColumn(\"pickup_date\", F.to_date(\"pickup_hour\"))\n",
    "\n",
    "# Aggregate trips per day per zone\n",
    "daily_counts = (\n",
    "    daily_zone.groupBy(\"PULocationID\", \"pickup_date\")\n",
    "    .agg(F.count(\"*\").alias(\"trips\"))\n",
    ")\n",
    "\n",
    "# Now average those daily trip totals for each zone\n",
    "zone_avg_daily = (\n",
    "    daily_counts.groupBy(\"PULocationID\")\n",
    "    .agg(F.avg(\"trips\").alias(\"avg_trips_per_day\"))\n",
    ")\n",
    "zone_avg_pd = zone_avg_daily.toPandas()\n",
    "# Convert ID type to match\n",
    "zones_geo[\"location_id\"] = zones_geo[\"location_id\"].astype(int)\n",
    "\n",
    "zones_merged_avg = zones_geo.merge(\n",
    "    zone_avg_pd, left_on=\"location_id\", right_on=\"PULocationID\", how=\"left\"\n",
    ")\n",
    "\n",
    "zones_merged_avg[\"avg_trips_per_day\"] = zones_merged_avg[\"avg_trips_per_day\"].fillna(0)\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.choropleth_mapbox(\n",
    "    zones_merged_avg,\n",
    "    geojson=zones_merged_avg.geometry.__geo_interface__,\n",
    "    locations=zones_merged_avg.index,\n",
    "    color=\"avg_trips_per_day\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    center={\"lat\": 40.75, \"lon\": -73.97},\n",
    "    zoom=9.8,\n",
    "    opacity=0.8,\n",
    "    color_continuous_scale=\"YlOrRd\",\n",
    "    title=\"Average Daily Taxi Demand by Pickup Zone\",\n",
    ")\n",
    "\n",
    "fig.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118a810d",
   "metadata": {},
   "source": [
    "Demand peaks around 6 pm , before decreasing throughout the night, eventually reaching it's minimum between 3 and 5 am. The number of trips rises steeply between 5 and 9 am, and then continues to grow at a slower steady pace throughout the late morning and afternoon before reaching peak hours in the evening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58948880",
   "metadata": {},
   "source": [
    "## Question 2: Which NYC zones have the highest pickup activity? ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e38553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2: Which NYC zones have the highest pickup activity?\n",
    "zone_totals = combined_df.groupBy('PULocationID').agg(count('*').alias('total_trips')).orderBy(col('total_trips').desc())\n",
    "zone_totals.show(20)\n",
    "\n",
    "#zone_totals.coalesce(1).write.mode('overwrite').csv('outputs/zone_totals.csv', header=True)\n",
    "zone_totals.write.mode('overwrite').parquet('outputs/zone_totals.parquet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2e1320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "# Compute pickups per zone\n",
    "zone_demand = (\n",
    "    taxi_df\n",
    "    .groupBy(\"PULocationID\")\n",
    "    .agg(count(\"*\").alias(\"total_pickups\"))\n",
    "    .orderBy(col(\"total_pickups\").desc())\n",
    ")\n",
    "\n",
    "zone_pd = zone_demand.toPandas()\n",
    "\n",
    "import plotly.express as px\n",
    "fig = px.bar(\n",
    "    zone_pd.head(20),  # top 20 busiest zones\n",
    "    x='PULocationID',\n",
    "    y='total_pickups',\n",
    "    title='Top 20 NYC Pickup Zones by Activity',\n",
    "    text_auto=True,\n",
    "    template='plotly_dark'\n",
    ")\n",
    "fig.update_layout(xaxis_title='Pickup Zone (ID)', yaxis_title='Total Pickups')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5bf41a",
   "metadata": {},
   "source": [
    "### Analysis ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a45d35",
   "metadata": {},
   "source": [
    "The results show that the highest taxi pickup activity is heavily concentrated in Manhattan, particularly in the Upper East Side and Midtown regions. The busiest zones include Upper East Side North (PULocationID 237), Midtown Center (161), and Upper East Side South (236), each recording around four million or more total pickups. Other major hotspots such as Midtown North, Murray Hill–Kips Bay, Times Square, and several Upper West Side zones also rank within the top 20. These areas are characterized by dense residential neighborhoods, major business districts, high tourism, and large transit hubs, all of which contribute to consistently strong taxi demand. Overall, the results highlight that Manhattan dominates taxi pickup activity across the city."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0905549",
   "metadata": {},
   "source": [
    "## Question 3: How does rain affect taxi demand / number of pickups ? ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a922bb9",
   "metadata": {},
   "source": [
    "Does rain increase or decrease taxi demand on a per-hour basis? (Did raining hours have more pickups than non-rain hours?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e657a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using 2 groups: raining vs not raining \n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "hourly_counts = (\n",
    "    combined_df\n",
    "    .groupBy(\"pickup_hour\", \"hour\", \"is_rainy\")\n",
    "    .agg(F.count(\"*\").alias(\"trip_count\"))\n",
    ")\n",
    "avg_by_rain = (\n",
    "    hourly_counts\n",
    "    .groupBy(\"is_rainy\")\n",
    "    .agg(F.avg(\"trip_count\").alias(\"avg_trips_per_hour\"))\n",
    "    .orderBy(\"is_rainy\")  \n",
    ")\n",
    "avg_by_rain.show()\n",
    "\n",
    "#4 groups based on precipitation amt \n",
    "combined_df_prec_levels = (\n",
    "    combined_df\n",
    "    .withColumn(\n",
    "        \"precip_level\",\n",
    "        F.when(F.col(\"rain_mm\") == 0, \"None\")\n",
    "         .when((F.col(\"rain_mm\") > 0) & (F.col(\"rain_mm\") <= 1), \"Light\")\n",
    "         .when((F.col(\"rain_mm\") > 1) & (F.col(\"rain_mm\") <= 5), \"Moderate\")\n",
    "         .otherwise(\"Heavy\")\n",
    "    )\n",
    ")\n",
    "hourly_counts_prec_levels = (\n",
    "    combined_df_prec_levels\n",
    "    .groupBy(\"pickup_hour\", \"hour\", \"precip_level\")\n",
    "    .agg(F.count(\"*\").alias(\"trip_count\"))\n",
    ")\n",
    "avg_by_precip = (\n",
    "    hourly_counts_prec_levels\n",
    "    .groupBy(\"precip_level\")\n",
    "    .agg(F.avg(\"trip_count\").alias(\"avg_trips_per_hour\"))\n",
    "    .orderBy(\"precip_level\")\n",
    ")\n",
    "\n",
    "avg_by_precip.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6400cf6d",
   "metadata": {},
   "source": [
    "Does rain change the distribution of demand across time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff37ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 groups \n",
    "hourly_distribution = (\n",
    "    hourly_counts\n",
    "    .groupBy(\"hour\", \"is_rainy\")\n",
    "    .agg(F.avg(\"trip_count\").alias(\"avg_trips\"))\n",
    "    .orderBy(\"hour\", \"is_rainy\")\n",
    ")\n",
    "\n",
    "hourly_pivot = (\n",
    "    hourly_distribution\n",
    "    .groupBy(\"hour\")\n",
    "    .pivot(\"is_rainy\", [0, 1])\n",
    "    .agg(F.first(\"avg_trips\"))\n",
    "    .withColumnRenamed(\"0\", \"avg_trips_clear\")\n",
    "    .withColumnRenamed(\"1\", \"avg_trips_rain\")\n",
    "    .orderBy(\"hour\")\n",
    ")\n",
    "hourly_pivot.show(24)\n",
    "\n",
    "##Plot results:\n",
    "\n",
    "import pandas\n",
    "import plotly.express as px\n",
    "hourly_pd = hourly_pivot.toPandas()\n",
    "fig = px.line(\n",
    "    hourly_pd,\n",
    "    x=\"hour\",\n",
    "    y=[\"avg_trips_clear\", \"avg_trips_rain\"],\n",
    "    title=\"Hourly Taxi Demand: Rain vs Clear\",\n",
    "    labels={\"value\": \"Average Trips\", \"variable\": \"Weather\"},\n",
    "    markers=True,\n",
    "    template=\"plotly_dark\"\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis=dict(dtick=1),\n",
    "    legend_title_text=\"Condition\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1b1ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4 groups \n",
    "import plotly.express as px\n",
    "\n",
    "hourly_distribution_prec_levels = (\n",
    "    hourly_counts_prec_levels\n",
    "    .groupBy(\"hour\", \"precip_level\")\n",
    "    .agg(F.avg(\"trip_count\").alias(\"avg_trips\"))\n",
    "    .orderBy(\"hour\", \"precip_level\")\n",
    ")\n",
    "hourly_pivot_prec_levels = (\n",
    "    hourly_distribution_prec_levels\n",
    "    .groupBy(\"hour\")\n",
    "    .pivot(\"precip_level\", [\"None\", \"Light\", \"Moderate\", \"Heavy\"])\n",
    "    .agg(F.first(\"avg_trips\"))\n",
    "    .orderBy(\"hour\")\n",
    ")\n",
    "hourly_pivot_prec_levels.show(24)\n",
    "\n",
    "prec_levels_pd = hourly_pivot_prec_levels.toPandas()\n",
    "prec_levels_pd = prec_levels_pd.rename(columns={\n",
    "    \"None\": \"No Rain\",\n",
    "    \"Light\": \"Light Rain\",\n",
    "    \"Moderate\": \"Moderate Rain\",\n",
    "    \"Heavy\": \"Heavy Rain\"\n",
    "})\n",
    "fig = px.line(\n",
    "    prec_levels_pd,\n",
    "    x=\"hour\",\n",
    "    y=[\"No Rain\", \"Light Rain\", \"Moderate Rain\", \"Heavy Rain\"],\n",
    "    title=\"Hourly Taxi Demand by Precipitation Level\",\n",
    "    labels={\"value\": \"Average Trips\", \"variable\": \"Precipitation\"},\n",
    "    markers=True,\n",
    "    template=\"plotly_dark\"\n",
    ")\n",
    "\n",
    "fig.update_layout(xaxis=dict(dtick=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434f0a5c",
   "metadata": {},
   "source": [
    "### Written Analysis ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2162b17",
   "metadata": {},
   "source": [
    "These results suggest that in general, rain does not significantly affect taxi demand, but that more severe levels of rain decrease demand. Lighter to moderate amounts of precipitation show little affect on total trips , as well as the distribution of demand throughout the day, meaning that the average demand for a given hour of the day is not impacted significantly by light to moderate rain. There does seem to be a slight decrease in demand for light and moderate rain compared to no rain, but it is no where near proportional to the drop in demand when there is heavy precipitation. \n",
    "\n",
    "We initially hypothesized that more rain might increase the number of taxi trips, because people would want to avoid walking in the rain. However, it seems that instead rain might make people less likely to be out and about, therefore decreasing the number of taxi rides needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b894ef75",
   "metadata": {},
   "source": [
    "## Question 4: Do colder temperatures lead to higher taxi usage? ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f15143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "combined_df_temp = (\n",
    "    combined_df\n",
    "    .withColumn(\n",
    "        \"temp_level\",\n",
    "        F.when(F.col(\"temperature_c\") < 0, \"Very Cold\")\n",
    "         .when(F.col(\"temperature_c\") < 5, \"Cold\")\n",
    "         .when(F.col(\"temperature_c\") < 15, \"Cool\")\n",
    "         .otherwise(\"Warm\")\n",
    "    )\n",
    ")\n",
    "\n",
    "hourly_counts_temp = (\n",
    "    combined_df_temp\n",
    "    .groupBy(\"pickup_hour\", \"hour\", \"temp_level\")\n",
    "    .agg(F.count(\"*\").alias(\"trip_count\"))\n",
    ")\n",
    "\n",
    "avg_by_temp = (\n",
    "    hourly_counts_temp\n",
    "    .groupBy(\"temp_level\")\n",
    "    .agg(F.avg(\"trip_count\").alias(\"avg_trips_per_hour\"))\n",
    "    .orderBy(\"avg_trips_per_hour\", ascending=False)\n",
    ")\n",
    "avg_by_temp.show()\n",
    "hourly_distribution_temp = (\n",
    "    hourly_counts_temp\n",
    "    .groupBy(\"hour\", \"temp_level\")\n",
    "    .agg(F.avg(\"trip_count\").alias(\"avg_trips\"))\n",
    "    .orderBy(\"hour\", \"temp_level\")\n",
    ")\n",
    "hourly_distribution_temp_pivot = (\n",
    "    hourly_distribution_temp\n",
    "    .groupBy(\"hour\")\n",
    "    .pivot(\"temp_level\", [\"Very Cold\", \"Cold\", \"Cool\", \"Warm\"])\n",
    "    .avg(\"avg_trips\")\n",
    "    .orderBy(\"hour\")\n",
    ")\n",
    "hourly_distribution_temp_pivot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf5ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "hourly_temp_pd = hourly_distribution_temp.toPandas()\n",
    "\n",
    "fig = px.line(\n",
    "    hourly_temp_pd,\n",
    "    x=\"hour\",\n",
    "    y=\"avg_trips\",\n",
    "    color=\"temp_level\",\n",
    "    title=\"Taxi Demand by Hour Under Different Temperature Levels\",\n",
    "    markers=True,\n",
    "    template=\"plotly_dark\"\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis=dict(dtick=1),\n",
    "    legend_title_text=\"Temperature Level\"\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4663733e",
   "metadata": {},
   "source": [
    "### Written Analysis ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d32544b",
   "metadata": {},
   "source": [
    "Here we can very clearly see that temperature has a direct impact on taxi demand. Very cold temperatures have the highest taxi demand at all hours of the day, and contribute to an even larger peak during the typical overall peak hours. Cold temperatures have a similar but lesser effect, and cool temperatures hover close to warm temperatures or slightly higher. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db20125",
   "metadata": {},
   "source": [
    "## Question 5: Are trip durations longer during bad weather? ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc8ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_df_1 = combined_df.withColumn(\n",
    "    \"duration_min\",\n",
    "    (F.unix_timestamp(\"tpep_dropoff_datetime\") -\n",
    "     F.unix_timestamp(\"tpep_pickup_datetime\")) / 60\n",
    ")\n",
    "avg_duration_1 = (\n",
    "    duration_df_1\n",
    "    .groupBy(\"is_rainy\")\n",
    "    .agg(F.avg(\"duration_min\").alias(\"avg_duration_min\"))\n",
    ")\n",
    "avg_duration_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e59c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_precip = combined_df.withColumn(\n",
    "    \"precip_level\",\n",
    "    F.when(F.col(\"precip_mm\") == 0, \"0. None\")\n",
    "     .when(F.col(\"precip_mm\") < 1, \"1. Light (<1mm)\")\n",
    "     .when(F.col(\"precip_mm\") < 3, \"2. Moderate (1–3mm)\")\n",
    "     .otherwise(\"3. Heavy (>3mm)\")\n",
    ")\n",
    "avg_duration_precip = (\n",
    "    duration_precip\n",
    "    .groupBy(\"precip_level\")\n",
    "    .agg(F.avg(\"duration_min\").alias(\"avg_duration_min\"))\n",
    "    .orderBy(\"precip_level\")\n",
    ")\n",
    "\n",
    "avg_duration_precip.show()\n",
    "\n",
    "duration_quantiles = (\n",
    "    duration_precip\n",
    "    .groupBy(\"precip_level\")\n",
    "    .agg(F.expr(\"percentile(duration_min, 0.5)\").alias(\"median_duration\"),\n",
    "         F.expr(\"percentile(duration_min, 0.9)\").alias(\"p90_duration\"))\n",
    ")\n",
    "pd_precip = avg_duration_precip.toPandas()\n",
    "\n",
    "import plotly.express as px\n",
    "fig = px.bar(\n",
    "    pd_precip,\n",
    "    x=\"precip_level\",\n",
    "    y=\"avg_duration_min\",\n",
    "    title=\"Average Trip Duration by Precipitation Level\",\n",
    "    text_auto=\".2f\",\n",
    "    template=\"plotly_dark\"\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98204619",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_temp = combined_df.withColumn(\n",
    "    \"temp_level\",\n",
    "    F.when(F.col(\"temperature_c\") < 5, \"Cold (<5°C)\")\n",
    "    .when(F.col(\"temperature_c\") > 25, \"Hot (>25°C)\")\n",
    "    .otherwise(\"Mild (5–25°C)\")\n",
    ")\n",
    "\n",
    "avg_duration_temp = (\n",
    "    duration_temp\n",
    "    .groupBy(\"temp_level\")\n",
    "    .agg(F.avg(\"duration_min\").alias(\"avg_duration_min\"))\n",
    "    .orderBy(\"temp_level\")\n",
    ")\n",
    "\n",
    "avg_duration_temp.show()\n",
    "\n",
    "temp_stats = (\n",
    "    duration_temp\n",
    "    .groupBy(\"temp_level\")\n",
    "    .agg(\n",
    "        F.avg(\"duration_min\").alias(\"avg_duration\"),\n",
    "        F.expr(\"percentile(duration_min, 0.5)\").alias(\"median_duration\")\n",
    "    )\n",
    "    .orderBy(\"temp_level\")\n",
    ")\n",
    "\n",
    "pd_temp = temp_stats.toPandas()\n",
    "\n",
    "fig = px.bar(\n",
    "    pd_temp,\n",
    "    x=\"temp_level\",\n",
    "    y=[\"avg_duration\", \"median_duration\"],\n",
    "    barmode=\"group\",\n",
    "    title=\"Trip Duration vs Temperature Category\",\n",
    "    labels={\"value\": \"Duration (minutes)\", \"temp_level\": \"Temperature Level\"},\n",
    "    text_auto=\".1f\",\n",
    "    template=\"plotly_dark\"\n",
    ")\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eafdf47",
   "metadata": {},
   "source": [
    "### Analysis ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675de3b6",
   "metadata": {},
   "source": [
    "Based on these findings, it appears that temperature and precipitation both have very little to no effect on trip duration. Any observable difference is more likely due to traffic patterns rather than customer habits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7b6487",
   "metadata": {},
   "source": [
    "## Question 6: Which zones experience the highest fare surges?  ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab509bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6: Which zones experience the highest fare surges?\n",
    "from pyspark.sql.functions import first\n",
    "\n",
    "zone_fare_weather = combined_df.groupBy('PULocationID','is_rainy').agg(avg('fare_amount').alias('avg_fare'))\n",
    "zone_fare_pivot = zone_fare_weather.groupBy('PULocationID').pivot('is_rainy', [0,1]).agg(first('avg_fare'))\n",
    "# rename pivot columns if they exist\n",
    "cols = zone_fare_pivot.columns\n",
    "if '0' in cols:\n",
    "    zone_fare_pivot = zone_fare_pivot.withColumnRenamed('0','fare_clear')\n",
    "if '1' in cols:\n",
    "    zone_fare_pivot = zone_fare_pivot.withColumnRenamed('1','fare_rainy')\n",
    "\n",
    "zone_fare_pivot = zone_fare_pivot.withColumn('pct_increase', (col('fare_rainy') - col('fare_clear'))/col('fare_clear')*100)\n",
    "zone_fare_pivot.orderBy(col('pct_increase').desc()).show(20)\n",
    "\n",
    "#zone_fare_pivot.coalesce(1).write.mode('overwrite').csv('outputs/zone_fare_pivot.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5935f2",
   "metadata": {},
   "source": [
    "We compared average taxi fares from each pickup zone during clear conditions versus rainy conditions. Several zones showed significant fare increases, in some cases more than 40–60% higher when it was raining. Because NYC yellow taxis do not use surge pricing, these increases are most likely driven by travel delays caused by rain, such as heavier traffic congestion, reduced road speeds, and longer trip durations. Zones near major transit choke-points or dense commercial areas appear to be the most affected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5102c3a",
   "metadata": {},
   "source": [
    "## Question 7: What is the correlation between precipitation and city-wide taxi demand, and between temperature and city-wide taxi demand? ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae03f7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "hourly = combined_df.groupBy(\"pickup_hour\", \"hour\").agg(\n",
    "    F.sum(\"trip_distance\").alias(\"total_distance\"),\n",
    "    F.count(\"*\").alias(\"trip_count\"),\n",
    "    F.avg(\"rain_mm\").alias(\"rain_mm\"),\n",
    "    F.avg(\"temperature_c\").alias(\"temperature_c\")\n",
    ")\n",
    "corr_by_hour = (\n",
    "    hourly.groupBy(\"hour\")\n",
    "    .agg(F.corr(\"rain_mm\", \"trip_count\").alias(\"corr_rain_demand\"))\n",
    "    .orderBy(\"hour\")\n",
    ")\n",
    "corr_by_hour.show(24)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ca0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, avg\n",
    "\n",
    "hourly_weather = combined_df.groupBy(\n",
    "    \"year\", \"month\", \"day\", \"hour\"\n",
    ").agg(\n",
    "    count(\"*\").alias(\"trips\"),\n",
    "    avg(\"rain_mm\").alias(\"rain_mm\")\n",
    ")\n",
    "df_clean = hourly_weather.dropna(subset=[\"rain_mm\", \"trips\"]).toPandas()\n",
    "corr = df_clean['rain_mm'].corr(df_clean['trips'])\n",
    "print(f\"Correlation between rain and taxi demand: {corr:.3f}\")\n",
    "fig = px.scatter(\n",
    "    df_clean,\n",
    "    x='rain_mm',\n",
    "    y='trips',\n",
    "    trendline='ols',\n",
    "    title=f\"Hourly Rain vs Taxi Demand (Correlation = {corr:.2f})\",\n",
    "    template='plotly_dark'\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Rain (mm)\",\n",
    "    yaxis_title=\"Number of Trips\"\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5146ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pyspark.sql.functions as F\n",
    "\"\"\" \n",
    "rain_vs_demand = hourly.select(\"rain_mm\", \"trip_count\")\n",
    "rain_pd = rain_vs_demand.toPandas()\n",
    "rain_pd = rain_pd.dropna(subset=['rain_mm', 'trip_count'])\n",
    "corr = rain_pd['rain_mm'].corr(rain_pd['trip_count'])\n",
    "print(f\"Correlation between rain and taxi demand: {corr:.3f}\")\n",
    "fig = px.scatter(\n",
    "    rain_pd,\n",
    "    x='rain_mm',\n",
    "    y='trip_count',\n",
    "    trendline='ols',\n",
    "    title=f\"Hourly Rain vs Taxi Demand (Correlation = {corr:.3f})\",\n",
    "    template='plotly_dark'\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Rainfall (mm per hour)\",\n",
    "    yaxis_title=\"Taxi Trips per Hour\"\n",
    ")\n",
    "fig.show() \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99c4047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "corr_temp_by_hour = (\n",
    "    hourly.groupBy(\"hour\")\n",
    "    .agg(F.corr(\"temperature_c\", \"trip_count\").alias(\"corr_temp_demand\"))\n",
    "    .orderBy(\"hour\")\n",
    ")\n",
    "\n",
    "corr_temp_by_hour.show(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98e5f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" temp_pd = hourly.select(\"temperature_c\", \"trip_count\").toPandas()\n",
    "corr_temp = temp_pd['temperature_c'].corr(temp_pd['trip_count'])\n",
    "print(f\"Correlation between temperature and taxi demand: {corr_temp:.3f}\")\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(\n",
    "    temp_pd,\n",
    "    x='temperature_c',\n",
    "    y='trip_count',\n",
    "    trendline='ols',   # remove this line if you still get statsmodels error\n",
    "    title=f\"Hourly Temperature vs Taxi Demand (Correlation = {corr_temp:.2f})\",\n",
    "    template='plotly_dark'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Temperature (°C)\",\n",
    "    yaxis_title=\"Taxi Trips per Hour\"\n",
    ")\n",
    "\n",
    "fig.show()\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeb3c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, avg\n",
    "import plotly.express as px\n",
    "\n",
    "# Create the same structure but for temperature\n",
    "hourly_temp = combined_df.groupBy(\n",
    "    \"year\", \"month\", \"day\", \"hour\"\n",
    ").agg(\n",
    "    count(\"*\").alias(\"trips\"),\n",
    "    avg(\"temperature_c\").alias(\"temperature_c\")\n",
    ")\n",
    "\n",
    "# Convert to Pandas + drop missing\n",
    "df_clean = hourly_temp.dropna(subset=[\"temperature_c\", \"trips\"]).toPandas()\n",
    "\n",
    "# Compute correlation\n",
    "corr = df_clean['temperature_c'].corr(df_clean['trips'])\n",
    "print(f\"Correlation between temperature and taxi demand: {corr:.3f}\")\n",
    "\n",
    "# Plot\n",
    "fig = px.scatter(\n",
    "    df_clean,\n",
    "    x='temperature_c',\n",
    "    y='trips',\n",
    "    trendline='ols',\n",
    "    title=f\"Hourly Temperature vs Taxi Demand (Correlation = {corr:.3f})\",\n",
    "    template='plotly_dark'\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Temperature (°C)\",\n",
    "    yaxis_title=\"Number of Trips\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d51d40",
   "metadata": {},
   "source": [
    "Analysis of hourly correlations shows that rain has only a weak and inconsistent relationship with taxi demand, with values hovering near zero across all hours, suggesting that precipitation alone does not reliably increase or decrease citywide ridership. In contrast, colder temperatures show a more consistent negative correlation with demand, indicating that taxi use tends to rise as temperatures drop, likely because walking and other outdoor travel becomes less comfortable. Overall, temperature appears to be a more reliable driver of demand than rain, while precipitation’s impact is smaller and more context-dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21049454",
   "metadata": {},
   "source": [
    "## Question 8: What are the best predictors of hourly taxi demand ?  ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a172aac3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cb1063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8: Best predictors of hourly taxi demand using RandomForest feature importance\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Prepare hourly weather averaged features\n",
    "hourly_weather_avg = weather_df.groupBy('weather_time') \\\n",
    "    .agg(avg('temperature_c').alias('avg_temp'), avg('rain_mm').alias('avg_rain'), avg('windspeed_kmh').alias('avg_wind')) \\\n",
    "    .withColumnRenamed('weather_time', 'pickup_hour')\n",
    "\n",
    "ml_df = city_hourly.join(hourly_weather_avg, on='pickup_hour', how='left').na.fill(0)\n",
    "ml_df = ml_df.withColumn('hour', hour(col('pickup_hour'))).withColumn('day_of_week', dayofweek(col('pickup_hour')))\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['hour','day_of_week','avg_temp','avg_rain','avg_wind'], outputCol='features')\n",
    "rf = RandomForestRegressor(featuresCol='features', labelCol='trip_count', numTrees=50)\n",
    "pipeline = Pipeline(stages=[assembler, rf])\n",
    "\n",
    "train_df, test_df = ml_df.randomSplit([0.8,0.2], seed=42)\n",
    "model = pipeline.fit(train_df)\n",
    "preds = model.transform(test_df)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol='trip_count', predictionCol='prediction', metricName='rmse')\n",
    "print('RMSE:', evaluator.evaluate(preds))\n",
    "\n",
    "rf_model = model.stages[-1]\n",
    "print('Feature importances:', rf_model.featureImportances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b779d72",
   "metadata": {},
   "source": [
    "The model’s feature importance scores show that time-based variables are by far the strongest predictors, with hour of the day accounting for roughly 83% of the predictive power and day of week contributing another 6%. Weather-related features played a much smaller role: temperature showed a modest effect (~8%), while rain and wind contributed very little. This indicates that demand in New York City is primarily driven by predictable daily and weekly travel patterns rather than short-term weather changes, with weather factors influencing demand only marginally compared to people’s regular commuting schedules and activity cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f54ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hourly_weather = combined_df.groupBy(\n",
    "    \"year\", \"month\", \"day\", \"hour\"\n",
    ").agg(\n",
    "    count(\"*\").alias(\"trip_count\"),\n",
    "    avg(\"rain_mm\").alias(\"rain_mm\")\n",
    ")\n",
    "\n",
    "hourly_weather = hourly_weather.withColumn(\n",
    "    \"pickup_hour\",\n",
    "    to_timestamp(concat_ws(\" \", concat_ws(\"-\", \"year\", \"month\", \"day\"), concat_ws(\":\", \"hour\")))\n",
    ")\n",
    "hourly_weather = hourly_weather.dropna(subset=[\"rain_mm\", \"trip_count\"]).toPandas()\n",
    "# --- Feature Engineering ---\n",
    "df = hourly_weather\n",
    "df['hour'] = df['pickup_hour'].dt.hour\n",
    "df['weekday'] = df['pickup_hour'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "df['month'] = df['pickup_hour'].dt.month\n",
    "df['is_weekend'] = df['weekday'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Clean missing values\n",
    "df = df.dropna(subset=['trip_count'])\n",
    "df = df.fillna(0)\n",
    "\n",
    "# --- Define features and target ---\n",
    "feature_cols = ['hour', 'weekday', 'month', 'is_weekend', 'rain_mm']\n",
    "X = df[feature_cols]\n",
    "y = df['trip_count']\n",
    "\n",
    "# --- Train/Test Split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Train Model ---\n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# --- Evaluate Performance ---\n",
    "y_pred = rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Model R² score: {r2:.3f}\")\n",
    "\n",
    "# --- Feature Importance ---\n",
    "importances = pd.Series(rf.feature_importances_, index=feature_cols).sort_values(ascending=True)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "importances.plot(kind='barh', color='skyblue')\n",
    "plt.title(\"Feature Importance: Predictors of Hourly Taxi Demand\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedc444f",
   "metadata": {},
   "source": [
    "## Question 9: Forecast next-day demand using lag features + RandomForest ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571e9e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9: Forecast next-day demand using lag features + RandomForest\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lag\n",
    "\n",
    "city_hourly = city_hourly.orderBy('pickup_hour')\n",
    "w = Window.orderBy('pickup_hour')\n",
    "\n",
    "lagged = city_hourly.withColumn('lag_1', lag('trip_count',1).over(w)).withColumn('lag_24', lag('trip_count',24).over(w)).na.fill(0)\n",
    "lagged = lagged.withColumn('hour', hour(col('pickup_hour'))).withColumn('day_of_week', dayofweek(col('pickup_hour')))\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['lag_1','lag_24','hour','day_of_week'], outputCol='features')\n",
    "ml_lag = assembler.transform(lagged).select('features','trip_count')\n",
    "\n",
    "train, test = ml_lag.randomSplit([0.8,0.2], seed=42)\n",
    "rf2 = RandomForestRegressor(featuresCol='features', labelCol='trip_count', numTrees=50)\n",
    "model2 = rf2.fit(train)\n",
    "preds2 = model2.transform(test)\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(labelCol='trip_count', predictionCol='prediction', metricName='rmse')\n",
    "print('Forecast RMSE:', evaluator.evaluate(preds2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f8e7af",
   "metadata": {},
   "source": [
    "To explore whether we could forecast taxi demand one day ahead, we created a predictive model using lag features, meaning information from previous hours. We added two key inputs: the demand from one hour earlier (lag_1) and the demand from the same hour on the previous day (lag_24), along with the hour of day and day of week. Using a Random Forest regression model, we trained the model to predict future hourly demand based on these patterns. The model achieved an RMSE of approximately 1,010, which is significantly lower than the baseline RMSE from earlier models without lagged features. This suggests that the strongest predictors of tomorrow’s demand are simply yesterday’s demand at the same time and the general hourly routine of the city, meaning New York’s taxi patterns are highly repetitive and stable across days. As a result, short-term historical demand proves to be more useful for forecasting than standalone weather or timing variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9cd7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hourly_weather = combined_df.groupBy(\n",
    "    \"year\", \"month\", \"day\", \"hour\"\n",
    ").agg(\n",
    "    count(\"*\").alias(\"trip_count\"),\n",
    "    avg(\"rain_mm\").alias(\"rain_mm\")\n",
    ")\n",
    "\n",
    "hourly_weather = hourly_weather.withColumn(\n",
    "    \"pickup_hour\",\n",
    "    to_timestamp(concat_ws(\" \", concat_ws(\"-\", \"year\", \"month\", \"day\"), concat_ws(\":\", \"hour\")))\n",
    ")\n",
    "hourly_weather = hourly_weather.dropna(subset=[\"rain_mm\", \"trip_count\"]).toPandas()\n",
    "df = hourly_weather\n",
    "# --- Feature Engineering ---\n",
    "df['hour'] = df['pickup_hour'].dt.hour\n",
    "df['weekday'] = df['pickup_hour'].dt.dayofweek\n",
    "df['month'] = df['pickup_hour'].dt.month\n",
    "df['is_weekend'] = df['weekday'].isin([5, 6]).astype(int)\n",
    "\n",
    "# --- Handle missing data ---\n",
    "df = df.dropna(subset=['trip_count'])\n",
    "df = df.fillna(0)\n",
    "\n",
    "# --- If you have these extra columns from weather data, include them ---\n",
    "# (If not, the model will still run with rain only)\n",
    "possible_weather_cols = ['rain_mm', 'temperature_2m (°C)', 'windspeed_10m (km/h)', 'humidity (%)']\n",
    "existing_weather_cols = [c for c in possible_weather_cols if c in df.columns]\n",
    "\n",
    "feature_cols = ['hour', 'weekday', 'month', 'is_weekend'] + existing_weather_cols\n",
    "\n",
    "# --- Define Features and Target ---\n",
    "X = df[feature_cols]\n",
    "y = df['trip_count']\n",
    "\n",
    "# --- Simulate \"next-day\" forecasting ---\n",
    "# Sort by time to simulate temporal prediction\n",
    "df_sorted = df.sort_values('pickup_hour')\n",
    "split_point = int(len(df_sorted) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_point], X.iloc[split_point:]\n",
    "y_train, y_test = y.iloc[:split_point], y.iloc[split_point:]\n",
    "\n",
    "# --- Train Model ---\n",
    "rf = RandomForestRegressor(n_estimators=300, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# --- Evaluate Forecasting Accuracy ---\n",
    "y_pred = rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Forecasting R² Score: {r2:.3f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f} trips\")\n",
    "\n",
    "# --- Plot Actual vs Predicted Demand ---\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(y_test.values[:200], label='Actual', color='lightgreen')\n",
    "plt.plot(y_pred[:200], label='Predicted', color='orange')\n",
    "plt.title(\"Next-Day Taxi Demand Forecast (Sample 200 Hours)\")\n",
    "plt.xlabel(\"Hour Index\")\n",
    "plt.ylabel(\"Trip Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- Feature Importance ---\n",
    "importances = pd.Series(rf.feature_importances_, index=feature_cols).sort_values(ascending=True)\n",
    "plt.figure(figsize=(8,5))\n",
    "importances.plot(kind='barh', color='skyblue')\n",
    "plt.title(\"Feature Importance: Taxi Demand Forecasting\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80e35ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "df['trip_count_next_day'] = df['trip_count'].shift(-24)\n",
    "\n",
    "# Drop rows where target is NaN (last 24 rows)\n",
    "df = df.dropna(subset=['trip_count_next_day'])\n",
    "\n",
    "# Features and target\n",
    "feature_cols = ['hour', 'weekday', 'month', 'is_weekend', 'rain_mm']\n",
    "X = df[feature_cols]\n",
    "y = df['trip_count_next_day']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"R² score: {r2:.3f}, RMSE: {rmse:.2f}\")\n",
    "\n",
    "# Feature importance\n",
    "importances = pd.Series(rf.feature_importances_, index=feature_cols).sort_values(ascending=True)\n",
    "plt.figure(figsize=(8,5))\n",
    "importances.plot(kind='barh', color='skyblue')\n",
    "plt.title(\"Feature Importance: Predictors of Next-Day Taxi Demand\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3352eb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df['rain_level'] = pd.cut(df['rain_mm'], bins=[-0.1, 2, 10, 100], labels=['Light', 'Moderate', 'Heavy'])\n",
    "\n",
    "# Compute average demand per hour and rain level\n",
    "heatmap_data = df.groupby(['hour', 'rain_level'])['trip_count'].mean().unstack()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(heatmap_data, annot=True, fmt=\".0f\", cmap='YlOrRd', cbar_kws={'label': 'Expected Trips'})\n",
    "plt.title(\"Next-Day Taxi Demand by Hour and Rain Level\")\n",
    "plt.xlabel(\"Rain Level\")\n",
    "plt.ylabel(\"Hour of Day\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408ff0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_data = df.groupby(['hour', 'rain_level', 'is_weekend'])['trip_count'].mean().reset_index()\n",
    "\n",
    "# Separate weekend and weekday\n",
    "weekday_data = heatmap_data[heatmap_data['is_weekend'] == 0].pivot(index='hour', columns='rain_level', values='trip_count')\n",
    "weekend_data = heatmap_data[heatmap_data['is_weekend'] == 1].pivot(index='hour', columns='rain_level', values='trip_count')\n",
    "\n",
    "# --- Plot Heatmaps ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18,6), sharey=True)\n",
    "\n",
    "sns.heatmap(weekday_data, annot=True, fmt=\".0f\", cmap='YlOrRd', ax=axes[0], cbar_kws={'label': 'Expected Trips'})\n",
    "axes[0].set_title(\"Weekday Taxi Demand by Hour & Rain Level\")\n",
    "axes[0].set_xlabel(\"Rain Level\")\n",
    "axes[0].set_ylabel(\"Hour of Day\")\n",
    "\n",
    "sns.heatmap(weekend_data, annot=True, fmt=\".0f\", cmap='YlOrRd', ax=axes[1], cbar_kws={'label': 'Expected Trips'})\n",
    "axes[1].set_title(\"Weekend Taxi Demand by Hour & Rain Level\")\n",
    "axes[1].set_xlabel(\"Rain Level\")\n",
    "axes[1].set_ylabel(\"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c10d286",
   "metadata": {},
   "source": [
    "## Q10 : Recommendations — compute zones with largest uplift and export ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d222707",
   "metadata": {},
   "source": [
    "### Rain uplift ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c781078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# average trips per hour by zone & rain\n",
    "zone_hourly = combined_df.groupBy(\"PULocationID\", \"is_rainy\") \\\n",
    "    .agg(F.count(\"*\").alias(\"trips\"), F.countDistinct(\"pickup_hour\").alias(\"hours\"))\n",
    "zone_avg = zone_hourly.withColumn(\"avg_trips_per_hour\", F.col(\"trips\") / F.col(\"hours\"))\n",
    "# pivot to compare rain vs clear\n",
    "zone_uplift = zone_avg.groupBy(\"PULocationID\").pivot(\"is_rainy\", [0,1]).agg(F.first(\"avg_trips_per_hour\"))\n",
    "zone_uplift = (\n",
    "    zone_uplift\n",
    "    .withColumnRenamed(\"0\", \"avg_clear\")\n",
    "    .withColumnRenamed(\"1\", \"avg_rain\")\n",
    "    .withColumn(\"pct_uplift\", (F.col(\"avg_rain\") - F.col(\"avg_clear\")) / F.col(\"avg_clear\") * 100)\n",
    "    .orderBy(\"pct_uplift\", ascending=False)\n",
    ")\n",
    "zone_uplift.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0041691c",
   "metadata": {},
   "source": [
    "### Temperature Uplift (Cold vs Mild) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd620eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "combined_binned = combined_df.withColumn(\n",
    "    \"temp_bin\",\n",
    "    F.when(F.col(\"temperature_c\") < 5, \"Cold (<5°C)\")\n",
    "     .when(F.col(\"temperature_c\") < 15, \"Cool (5–15°C)\")\n",
    "     .when(F.col(\"temperature_c\") < 25, \"Mild (15–25°C)\")\n",
    "     .otherwise(\"Hot (>25°C)\")\n",
    ")\n",
    "zone_temp = (\n",
    "    combined_binned\n",
    "    .groupBy(\"PULocationID\", \"temp_bin\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"trips\"),\n",
    "        F.countDistinct(\"pickup_hour\").alias(\"hours\")\n",
    "    )\n",
    ")\n",
    "zone_temp = zone_temp.withColumn(\n",
    "    \"avg_trips_per_hour\",\n",
    "    F.col(\"trips\") / F.col(\"hours\")\n",
    ")\n",
    "zone_temp_pivot = (\n",
    "    zone_temp\n",
    "    .groupBy(\"PULocationID\")\n",
    "    .pivot(\"temp_bin\", [\"Cold (<5°C)\", \"Cool (5–15°C)\", \"Mild (15–25°C)\", \"Hot (>25°C)\"])\n",
    "    .agg(F.first(\"avg_trips_per_hour\"))\n",
    ")\n",
    "\n",
    "zone_temp_results = zone_temp_pivot.withColumn(\n",
    "    \"pct_uplift_cold_vs_mild\",\n",
    "    (F.col(\"Cold (<5°C)\") - F.col(\"Mild (15–25°C)\")) / F.col(\"Mild (15–25°C)\") * 100\n",
    ")\n",
    "zone_temp_results.orderBy(\"pct_uplift_cold_vs_mild\", ascending=False).show(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3341a85",
   "metadata": {},
   "source": [
    "### Analysis ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fe755f",
   "metadata": {},
   "source": [
    "The uplift analysis highlights that weather influences taxi demand differently across the city’s pickup zones. A small number of zones show modest increases in demand during rain (up to roughly 28% uplift), suggesting these areas may rely more on taxis when conditions discourage walking or transit use. However, temperature appears to have a much stronger and more consistent impact: several zones show a 30–60% increase in demand during colder conditions compared to mild temperatures, indicating that cold weather is a more powerful driver of taxi usage than rain. These results suggest that demand shifts caused by weather are highly location-dependent, and that temperature-related effects are substantially more significant than precipitation when planning for fleet allocation or forecasting demand across NYC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5d1b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lag feature: previous day's same hour demand\n",
    "df = df.sort_values('pickup_hour')\n",
    "df['prev_day_demand'] = df['trip_count'].shift(24)\n",
    "\n",
    "# Drop rows without lag data\n",
    "df = df.dropna(subset=['prev_day_demand'])\n",
    "\n",
    "# Features & target\n",
    "feature_cols = ['hour', 'weekday', 'month', 'is_weekend', 'rain_mm', 'prev_day_demand']\n",
    "X = df[feature_cols]\n",
    "y = df['trip_count']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"Forecast R²: {r2:.3f}\")\n",
    "print(f\"MAE: {mae:.2f} trips\")\n",
    "print(f\"RMSE: {rmse:.2f} trips\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7ad12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['hour', 'weekday', 'month', 'is_weekend', 'rain_mm', 'prev_day_demand']\n",
    "\n",
    "# Scenarios for weather\n",
    "rain_scenarios = {\n",
    "    'no_rain': 0.0,\n",
    "    'light_rain': 2.0,\n",
    "    'heavy_rain': 10.0\n",
    "}\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "for scenario, rain_val in rain_scenarios.items():\n",
    "    X_scenario = df.copy()\n",
    "    X_scenario['rain_mm'] = rain_val\n",
    "    X_scenario_features = X_scenario[feature_cols]\n",
    "    \n",
    "    # Predict demand\n",
    "    y_pred = rf.predict(X_scenario_features)\n",
    "    \n",
    "    X_scenario[f'predicted_demand_{scenario}'] = y_pred\n",
    "    recommendations.append(X_scenario[['pickup_hour', f'predicted_demand_{scenario}']])\n",
    "\n",
    "# Merge scenarios\n",
    "rec_table = recommendations[0]\n",
    "for r in recommendations[1:]:\n",
    "    rec_table = rec_table.merge(r, on='pickup_hour')\n",
    "\n",
    "# Fleet allocation suggestion: add 10% buffer for heavy rain\n",
    "rec_table['fleet_suggestion'] = rec_table['predicted_demand_heavy_rain'] * 1.1\n",
    "rec_table['fleet_suggestion'] = rec_table['fleet_suggestion'].apply(np.ceil)  # round up\n",
    "\n",
    "# Show sample\n",
    "print(rec_table.head())\n",
    "\n",
    "# Save to CSV\n",
    "rec_table.to_csv(\"taxi_fleet_recommendations.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842ef041",
   "metadata": {},
   "source": [
    "### Additional Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cef02a",
   "metadata": {},
   "source": [
    "### Heatmaps ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed06b58",
   "metadata": {},
   "source": [
    "Comparison: Avg Pickups per hour - Non-Rainy hour vs Rainy hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91587ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "combined_df_2= combined_df.withColumn(\n",
    "    \"is_rainy_heavy\",\n",
    "    when(col(\"rain_mm\") > 1.0, 1).otherwise(0)\n",
    ")\n",
    "combined_df_2.printSchema()\n",
    "\n",
    "# Calculate avg trips per hour by zone and rain condition\n",
    "rain_zone_hourly = combined_df_2.groupBy(\"PULocationID\", \"is_rainy\") \\\n",
    "    .agg(F.count(\"*\").alias(\"total_trips\"),\n",
    "         F.countDistinct(\"pickup_hour\").alias(\"num_hours\"))\n",
    "\n",
    "# Calculate avg trips per hour\n",
    "rain_zone_hourly = rain_zone_hourly.withColumn(\n",
    "    \"avg_trips_per_hour\",\n",
    "    F.when(F.col(\"num_hours\") > 0, F.col(\"total_trips\") / F.col(\"num_hours\")).otherwise(0)\n",
    ")\n",
    "\n",
    "# Pivot so we have columns: trips_clear / trips_rainy\n",
    "rain_zone_pivot = rain_zone_hourly.groupBy(\"PULocationID\") \\\n",
    "    .pivot(\"is_rainy\", [0,1]) \\\n",
    "    .agg(F.first(\"avg_trips_per_hour\"))\n",
    "\n",
    "# Rename pivoted columns\n",
    "rain_zone_pivot = (\n",
    "    rain_zone_pivot\n",
    "    .withColumnRenamed(\"0\", \"avg_trips_clear\")\n",
    "    .withColumnRenamed(\"1\", \"avg_trips_rain\")\n",
    ")\n",
    "\n",
    "# Fill missing with zero (zones with no rain entries)\n",
    "rain_zone_pd = rain_zone_pivot.toPandas()\n",
    "zones_geo[\"location_id\"] = zones_geo[\"location_id\"].astype(int)\n",
    "\n",
    "zones_rain_merged = zones_geo.merge(\n",
    "    rain_zone_pd, left_on=\"location_id\", right_on=\"PULocationID\", how=\"left\"\n",
    ")\n",
    "\n",
    "zones_rain_merged[\"avg_trips_clear\"] = zones_rain_merged[\"avg_trips_clear\"].fillna(0)\n",
    "zones_rain_merged[\"avg_trips_rain\"] = zones_rain_merged[\"avg_trips_rain\"].fillna(0)\n",
    "import numpy as np\n",
    "\n",
    "zones_rain_merged[\"log_avg_clear\"] = np.log1p(zones_rain_merged[\"avg_trips_clear\"])\n",
    "\n",
    "\n",
    "\n",
    "fig = px.choropleth_mapbox(\n",
    "    zones_rain_merged,\n",
    "    geojson=zones_rain_merged.geometry.__geo_interface__,\n",
    "    locations=zones_rain_merged.index,\n",
    "    color=\"avg_trips_clear\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    center={\"lat\": 40.75, \"lon\": -73.97},\n",
    "    zoom=9.8,\n",
    "    opacity=0.85,\n",
    "    color_continuous_scale=\"Turbo\",\n",
    "    title=\"Average Taxi Pickups per Hour — Clear Weather\"\n",
    ")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig.show()\n",
    "fig2 = px.choropleth_mapbox(\n",
    "    zones_rain_merged,\n",
    "    geojson=zones_rain_merged.geometry.__geo_interface__,\n",
    "    locations=zones_rain_merged.index,\n",
    "    color=\"avg_trips_rain\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    center={\"lat\": 40.75, \"lon\": -73.97},\n",
    "    zoom=9.8,\n",
    "    opacity=0.85,\n",
    "    color_continuous_scale=\"Turbo\",\n",
    "    title=\"Average Taxi Pickups per Hour — Rainy Weather\"\n",
    ")\n",
    "fig2.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig2.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a450c500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "zones_rain_merged[\"log_avg_clear\"] = np.log1p(zones_rain_merged[\"avg_trips_clear\"])\n",
    "\n",
    "fig = px.choropleth_mapbox(\n",
    "    zones_rain_merged,\n",
    "    geojson=zones_rain_merged.geometry.__geo_interface__,\n",
    "    locations=zones_rain_merged.index,\n",
    "    color=\"log_avg_clear\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    center={\"lat\": 40.75, \"lon\": -73.97},\n",
    "    zoom=9.8,\n",
    "    opacity=0.85,\n",
    "    color_continuous_scale=\"Viridis\",  \n",
    "    title=\"Average Taxi Pickups (Clear Weather) — Log Scaled\"\n",
    ")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feffaed",
   "metadata": {},
   "source": [
    "**change below cell to use average not toal trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55699e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "\n",
    "# Create new rainy classification (>= 1mm precip)\n",
    "combined_df = combined_df.withColumn(\n",
    "    \"is_rainy\",\n",
    "    F.when(F.col(\"rain_mm\") >= 1, 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Compute avg trips per zone under clear vs rainy hours\n",
    "zone_weather = combined_df.groupBy(\"PULocationID\", \"is_rainy\").agg(\n",
    "    F.count(\"*\").alias(\"total_trips\"),\n",
    "    F.countDistinct(\"pickup_hour\").alias(\"num_hours\")\n",
    ")\n",
    "\n",
    "# Calculate avg trips per hour\n",
    "zone_weather = zone_weather.withColumn(\n",
    "    \"avg_trips_per_hour\",\n",
    "    F.when(F.col(\"num_hours\") > 0, F.col(\"total_trips\") / F.col(\"num_hours\")).otherwise(0)\n",
    ")\n",
    "\n",
    "zone_weather_pivot = (\n",
    "    zone_weather.groupBy(\"PULocationID\")\n",
    "    .pivot(\"is_rainy\", [0, 1])\n",
    "    .agg(F.first(\"avg_trips_per_hour\"))\n",
    ")\n",
    "\n",
    "zone_weather_pivot = (\n",
    "    zone_weather_pivot.withColumnRenamed(\"0\", \"avg_trips_clear\")\n",
    "                      .withColumnRenamed(\"1\", \"avg_trips_rain\")\n",
    "                      .fillna(0)\n",
    ")\n",
    "\n",
    "# Convert to pandas\n",
    "zone_pd = zone_weather_pivot.toPandas()\n",
    "\n",
    "# Log-scale for better color contrast on map\n",
    "zone_pd[\"log_clear\"] = np.log1p(zone_pd[\"avg_trips_clear\"])\n",
    "zone_pd[\"log_rain\"]  = np.log1p(zone_pd[\"avg_trips_rain\"])\n",
    "\n",
    "#Load NYC Taxi Zones GeoJSON & Merge\n",
    "zones_geo = gpd.read_file(\"taxi_zones.geojson\")\n",
    "zones_geo[\"location_id\"] = zones_geo[\"location_id\"].astype(int)\n",
    "\n",
    "zones_merged = zones_geo.merge(zone_pd, left_on=\"location_id\", right_on=\"PULocationID\", how=\"left\")\n",
    "zones_merged = zones_merged.fillna(0)\n",
    "\n",
    "# Also create zones_rain_merged for later use (same data)\n",
    "zones_rain_merged = zones_merged.copy()\n",
    "\n",
    "# avg pickups clear weather\n",
    "fig_clear = px.choropleth_mapbox(\n",
    "    zones_merged,\n",
    "    geojson=zones_merged.geometry.__geo_interface__,\n",
    "    locations=zones_merged.index,\n",
    "    color=\"log_clear\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    center={\"lat\": 40.75, \"lon\": -73.97},\n",
    "    zoom=9.8,\n",
    "    opacity=0.85,\n",
    "    color_continuous_scale=\"Turbo\",\n",
    "    title=\"Average Taxi Pickups — Clear Weather (Log Scaled)\"\n",
    ")\n",
    "fig_clear.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig_clear.show()\n",
    "\n",
    "#avg pickups rainy weather\n",
    "fig_rain = px.choropleth_mapbox(\n",
    "    zones_merged,\n",
    "    geojson=zones_merged.geometry.__geo_interface__,\n",
    "    locations=zones_merged.index,\n",
    "    color=\"log_rain\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    center={\"lat\": 40.75, \"lon\": -73.97},\n",
    "    zoom=9.8,\n",
    "    opacity=0.85,\n",
    "    color_continuous_scale=\"Turbo\",\n",
    "    title=\"Average Taxi Pickups — Rainy Weather (Log Scaled)\"\n",
    ")\n",
    "fig_rain.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig_rain.show()\n",
    "\n",
    "zones_rain_merged[\"pct_uplift_rain\"] = np.where(\n",
    "    zones_rain_merged[\"avg_trips_clear\"] > 0,\n",
    "    ((zones_rain_merged[\"avg_trips_rain\"] - zones_rain_merged[\"avg_trips_clear\"]) /\n",
    "     zones_rain_merged[\"avg_trips_clear\"]) * 100,\n",
    "    0\n",
    ")\n",
    "\n",
    "# Cap extreme values for better visualization\n",
    "zones_rain_merged[\"pct_uplift_rain\"] = zones_rain_merged[\"pct_uplift_rain\"].clip(lower=-100, upper=100)\n",
    "\n",
    "zones_rain_merged[\"log_avg_clear\"] = np.log1p(zones_rain_merged[\"avg_trips_clear\"])\n",
    "\n",
    "fig_clear = px.choropleth_mapbox(\n",
    "    zones_rain_merged,\n",
    "    geojson=zones_rain_merged.geometry.__geo_interface__,\n",
    "    locations=zones_rain_merged.index,\n",
    "    color=\"log_avg_clear\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    center={\"lat\": 40.75, \"lon\": -73.97},\n",
    "    zoom=9.8,\n",
    "    opacity=0.85,\n",
    "    color_continuous_scale=\"Viridis\",\n",
    "    title=\"Average Taxi Pickups (Clear Weather) — Log Scaled\"\n",
    ")\n",
    "fig_clear.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig_clear.show()\n",
    "\n",
    "#percent uplift\n",
    "fig_uplift = px.choropleth_mapbox(\n",
    "    zones_rain_merged,\n",
    "    geojson=zones_rain_merged.geometry.__geo_interface__,\n",
    "    locations=zones_rain_merged.index,\n",
    "    color=\"pct_uplift_rain\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    center={\"lat\": 40.75, \"lon\": -73.97},\n",
    "    zoom=9.8,\n",
    "    opacity=0.85,\n",
    "    color_continuous_scale=\"Turbo\",  # green=min, red=max\n",
    "    title=\"Percentage Change in Taxi Demand — Rain vs Clear (%)\"\n",
    ")\n",
    "fig_uplift.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig_uplift.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836352c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "\n",
    "#Temperature bucket classification\n",
    "combined_df_3 = combined_df.withColumn(\n",
    "    \"temp_bucket\",\n",
    "    F.when(F.col(\"temperature_c\") < 5, \"Cold (<5°C)\")\n",
    "     .when((F.col(\"temperature_c\") >= 15) & (F.col(\"temperature_c\") <= 25), \"Mild (15–25°C)\")\n",
    "     .otherwise(\"Other\")\n",
    ")\n",
    "\n",
    "# Compute avg pickups per zone & temperature category\n",
    "zone_temp = combined_df_3.groupBy(\"PULocationID\", \"temp_bucket\").agg(\n",
    "    F.count(\"*\").alias(\"total_trips\"),\n",
    "    F.countDistinct(\"pickup_hour\").alias(\"num_hours\")\n",
    ")\n",
    "\n",
    "# Calculate avg trips per hour\n",
    "zone_temp = zone_temp.withColumn(\n",
    "    \"avg_trips_per_hour\",\n",
    "    F.when(F.col(\"num_hours\") > 0, F.col(\"total_trips\") / F.col(\"num_hours\")).otherwise(0)\n",
    ")\n",
    "\n",
    "# Pivot so Cold and Mild become columns\n",
    "zone_temp_pivot = (\n",
    "    zone_temp.groupBy(\"PULocationID\")\n",
    "             .pivot(\"temp_bucket\", [\"Cold (<5°C)\", \"Mild (15–25°C)\"])\n",
    "             .agg(F.first(\"avg_trips_per_hour\"))\n",
    "             .fillna(0)\n",
    ")\n",
    "\n",
    "zone_temp_pd = zone_temp_pivot.toPandas()\n",
    "\n",
    "# Compute uplift: (Cold - Mild)/Mild * 100\n",
    "zone_temp_pd[\"pct_uplift_cold_vs_mild\"] = np.where(\n",
    "    zone_temp_pd[\"Mild (15–25°C)\"] > 0,\n",
    "    (zone_temp_pd[\"Cold (<5°C)\"] - zone_temp_pd[\"Mild (15–25°C)\"]) / zone_temp_pd[\"Mild (15–25°C)\"] * 100,\n",
    "    0\n",
    ")\n",
    "\n",
    "# Apply log scaling to demand (for heatmap clarity)\n",
    "zone_temp_pd[\"log_cold\"] = np.log1p(zone_temp_pd[\"Cold (<5°C)\"])\n",
    "zone_temp_pd[\"log_mild\"] = np.log1p(zone_temp_pd[\"Mild (15–25°C)\"])\n",
    "\n",
    "# Load GeoJSON and merge\n",
    "zones_geo = gpd.read_file(\"taxi_zones.geojson\")\n",
    "zones_geo[\"location_id\"] = zones_geo[\"location_id\"].astype(int)\n",
    "\n",
    "zones_temp_merged = zones_geo.merge(\n",
    "    zone_temp_pd, left_on=\"location_id\", right_on=\"PULocationID\", how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "# Cold Heatmap\n",
    "fig_cold = px.choropleth_mapbox(\n",
    "    zones_temp_merged,\n",
    "    geojson=zones_temp_merged.geometry.__geo_interface__,\n",
    "    locations=zones_temp_merged.index,\n",
    "    color=\"log_cold\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    center={\"lat\": 40.75, \"lon\": -73.97},\n",
    "    zoom=9.7,\n",
    "    opacity=0.85,\n",
    "    color_continuous_scale=\"Turbo\",\n",
    "    title=\"Heatmap: Average Taxi Pickups in COLD Weather (<5°C)\"\n",
    ")\n",
    "fig_cold.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig_cold.show()\n",
    "\n",
    "# Mild heatmap\n",
    "fig_mild = px.choropleth_mapbox(\n",
    "    zones_temp_merged,\n",
    "    geojson=zones_temp_merged.geometry.__geo_interface__,\n",
    "    locations=zones_temp_merged.index,\n",
    "    color=\"log_mild\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    center={\"lat\": 40.75, \"lon\": -73.97},\n",
    "    zoom=9.7,\n",
    "    opacity=0.85,\n",
    "    color_continuous_scale=\"Turbo\",\n",
    "    title=\"Heatmap: Average Taxi Pickups in MILD Weather (15–25°C)\"\n",
    ")\n",
    "fig_mild.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig_mild.show()\n",
    "\n",
    "fig_uplift = px.choropleth_mapbox(\n",
    "    zones_temp_merged,\n",
    "    geojson=zones_temp_merged.geometry.__geo_interface__,\n",
    "    locations=zones_temp_merged.index,\n",
    "    color=\"pct_uplift_cold_vs_mild\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    center={\"lat\": 40.75, \"lon\": -73.97},\n",
    "    zoom=9.7,\n",
    "    opacity=0.85,\n",
    "    color_continuous_scale=\"Turbo\",\n",
    "    title=\"Heatmap: Percentage Uplift in Demand — COLD vs MILD Weather (%)\"\n",
    ")\n",
    "fig_uplift.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig_uplift.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13380dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F, Window\n",
    "from pyspark.sql.functions import col, when\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "\n",
    "# Create temp bucket column (\"Cold (<5°C)\" or \"Not Cold\")\n",
    "combined_df_4 = combined_df.withColumn(\n",
    "    \"temp_bucket\",\n",
    "    when(col(\"temperature_c\") < 5, \"Cold (<5°C)\").otherwise(\"Not Cold\")\n",
    ")\n",
    "\n",
    "zone_temp = combined_df_4.groupBy(\"PULocationID\", \"temp_bucket\").agg(\n",
    "    F.count(\"*\").alias(\"total_trips\"),\n",
    "    F.countDistinct(\"pickup_hour\").alias(\"num_hours\")\n",
    ")\n",
    "\n",
    "# Calculate avg trips per hour\n",
    "zone_temp = zone_temp.withColumn(\n",
    "    \"avg_trips_per_hour\",\n",
    "    F.when(F.col(\"num_hours\") > 0, F.col(\"total_trips\") / F.col(\"num_hours\")).otherwise(0)\n",
    ")\n",
    "\n",
    "zone_temp_pivot = (\n",
    "    zone_temp.groupBy(\"PULocationID\")\n",
    "             .pivot(\"temp_bucket\", [\"Cold (<5°C)\", \"Not Cold\"])\n",
    "             .agg(F.first(\"avg_trips_per_hour\"))\n",
    "             .fillna(0)\n",
    ")\n",
    "\n",
    "# Convert to pandas\n",
    "zone_temp_pd = zone_temp_pivot.toPandas()\n",
    "\n",
    "zone_temp_pd[\"pct_uplift_cold_vs_notcold\"] = np.where(\n",
    "    zone_temp_pd[\"Not Cold\"] > 0,\n",
    "    (zone_temp_pd[\"Cold (<5°C)\"] - zone_temp_pd[\"Not Cold\"]) / zone_temp_pd[\"Not Cold\"] * 100,\n",
    "    0\n",
    ")\n",
    "\n",
    "# Log scale for clarity\n",
    "zone_temp_pd[\"log_cold\"] = np.log1p(zone_temp_pd[\"Cold (<5°C)\"])\n",
    "zone_temp_pd[\"log_notcold\"] = np.log1p(zone_temp_pd[\"Not Cold\"])\n",
    "\n",
    "zones_geo = gpd.read_file(\"taxi_zones.geojson\")\n",
    "zones_geo[\"location_id\"] = zones_geo[\"location_id\"].astype(int)\n",
    "\n",
    "zones_temp_merged = zones_geo.merge(\n",
    "    zone_temp_pd, left_on=\"location_id\", right_on=\"PULocationID\", how=\"left\"\n",
    ").fillna(0)\n",
    "fig_cold = px.choropleth_mapbox(\n",
    "    zones_temp_merged,\n",
    "    geojson=zones_temp_merged.geometry.__geo_interface__,\n",
    "    locations=zones_temp_merged.index,\n",
    "    color=\"log_cold\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    center={\"lat\": 40.75, \"lon\": -73.97},\n",
    "    zoom=9.7,\n",
    "    opacity=0.90,\n",
    "    color_continuous_scale=\"Turbo\",\n",
    "    title=\"Heatmap: Average Taxi Pickups in COLD Weather (< 5°C)\"\n",
    ")\n",
    "fig_cold.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig_cold.show()\n",
    "\n",
    "fig_notcold = px.choropleth_mapbox(\n",
    "    zones_temp_merged,\n",
    "    geojson=zones_temp_merged.geometry.__geo_interface__,\n",
    "    locations=zones_temp_merged.index,\n",
    "    color=\"log_notcold\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    center={\"lat\": 40.75, \"lon\": -73.97},\n",
    "    zoom=9.7,\n",
    "    opacity=0.90,\n",
    "    color_continuous_scale=\"Turbo\",\n",
    "    title=\"Heatmap: Average Taxi Pickups in NOT COLD Weather (≥ 5°C)\"\n",
    ")\n",
    "fig_notcold.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig_notcold.show()\n",
    "\n",
    "fig_uplift = px.choropleth_mapbox(\n",
    "    zones_temp_merged,\n",
    "    geojson=zones_temp_merged.geometry.__geo_interface__,\n",
    "    locations=zones_temp_merged.index,\n",
    "    color=\"pct_uplift_cold_vs_notcold\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    center={\"lat\": 40.75, \"lon\": -73.97},\n",
    "    zoom=9.7,\n",
    "    opacity=0.90,\n",
    "    color_continuous_scale=\"Turbo\",\n",
    "    title=\"Heatmap: % Uplift in Demand — Cold vs Not Cold (%)\"\n",
    ")\n",
    "fig_uplift.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig_uplift.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cf240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "\n",
    "# Define PM peak hours\n",
    "pm_peak_hours = [17, 18, 19]  # 5–7 PM\n",
    "\n",
    "# Classify temperature buckets & filter to PM peak only\n",
    "combined_df_peak = (\n",
    "    combined_df\n",
    "    .withColumn(\"temp_bucket\",\n",
    "        F.when(F.col(\"temperature_c\") < 5, \"Cold (<5°C)\")\n",
    "         .otherwise(\"Not Cold\")\n",
    "    )\n",
    "    .withColumn(\"hour\", F.hour(\"pickup_hour\"))\n",
    "    .filter(F.col(\"hour\").isin(pm_peak_hours))\n",
    ")\n",
    "\n",
    "# Compute avg pickups by zone & temperature category (PM peak only)\n",
    "zone_temp_peak = combined_df_peak.groupBy(\"PULocationID\", \"temp_bucket\").agg(\n",
    "    F.count(\"*\").alias(\"total_trips\"),\n",
    "    F.countDistinct(\"pickup_hour\").alias(\"num_hours\")\n",
    ")\n",
    "\n",
    "# Calculate avg trips per hour\n",
    "zone_temp_peak = zone_temp_peak.withColumn(\n",
    "    \"avg_trips\",\n",
    "    F.when(F.col(\"num_hours\") > 0, F.col(\"total_trips\") / F.col(\"num_hours\")).otherwise(0)\n",
    ")\n",
    "\n",
    "# Pivot so Cold / Not Cold are columns\n",
    "zone_temp_peak_pivot = (\n",
    "    zone_temp_peak.groupBy(\"PULocationID\")\n",
    "                  .pivot(\"temp_bucket\", [\"Cold (<5°C)\", \"Not Cold\"])\n",
    "                  .agg(F.first(\"avg_trips\"))\n",
    "                  .fillna(0)\n",
    ")\n",
    "\n",
    "zone_temp_peak_pd = zone_temp_peak_pivot.toPandas()\n",
    "\n",
    "# Percentage uplift (Cold vs Not Cold)\n",
    "zone_temp_peak_pd[\"pct_uplift_cold_vs_notcold\"] = np.where(\n",
    "    zone_temp_peak_pd[\"Not Cold\"] > 0,\n",
    "    (zone_temp_peak_pd[\"Cold (<5°C)\"] - zone_temp_peak_pd[\"Not Cold\"]) / zone_temp_peak_pd[\"Not Cold\"] * 100,\n",
    "    0\n",
    ")\n",
    "\n",
    "# Log scaling for clarity\n",
    "zone_temp_peak_pd[\"log_cold\"] = np.log1p(zone_temp_peak_pd[\"Cold (<5°C)\"])\n",
    "zone_temp_peak_pd[\"log_notcold\"] = np.log1p(zone_temp_peak_pd[\"Not Cold\"])\n",
    "\n",
    "# 6️⃣ Load GeoJSON & merge\n",
    "zones_geo = gpd.read_file(\"taxi_zones.geojson\")\n",
    "zones_geo[\"location_id\"] = zones_geo[\"location_id\"].astype(int)\n",
    "\n",
    "zones_temp_peak_merged = zones_geo.merge(\n",
    "    zone_temp_peak_pd, left_on=\"location_id\", right_on=\"PULocationID\", how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "# Define shared custom color scale red = highest\n",
    "custom_scale = [\"blue\",\"green\",\"yellow\",\"orange\",\"red\"]\n",
    "\n",
    "fig_cold_peak = px.choropleth_mapbox(\n",
    "    zones_temp_peak_merged,\n",
    "    geojson=zones_temp_peak_merged.geometry.__geo_interface__,\n",
    "    locations=zones_temp_peak_merged.index,\n",
    "    color=\"log_cold\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    center={\"lat\": 40.75, \"lon\": -73.97},\n",
    "    zoom=9.7,\n",
    "    opacity=0.85,\n",
    "    color_continuous_scale=custom_scale,\n",
    "    title=\"Heatmap: PM Peak Taxi Pickups — COLD Weather (<5°C)\"\n",
    ")\n",
    "fig_cold_peak.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig_cold_peak.show()\n",
    "\n",
    "fig_notcold_peak = px.choropleth_mapbox(\n",
    "    zones_temp_peak_merged,\n",
    "    geojson=zones_temp_peak_merged.geometry.__geo_interface__,\n",
    "    locations=zones_temp_peak_merged.index,\n",
    "    color=\"log_notcold\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    center={\"lat\": 40.75, \"lon\": -73.97},\n",
    "    zoom=9.7,\n",
    "    opacity=0.85,\n",
    "    color_continuous_scale=custom_scale,\n",
    "    title=\"Heatmap: PM Peak Taxi Pickups — NON-COLD Weather (>5°C)\"\n",
    ")\n",
    "fig_notcold_peak.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig_notcold_peak.show()\n",
    "\n",
    "# Calculate the actual min/max of the percent uplift to set a tighter color scale\n",
    "uplift_values = zones_temp_peak_merged[\"pct_uplift_cold_vs_notcold\"].dropna()\n",
    "uplift_min = uplift_values.min()\n",
    "uplift_max = uplift_values.max()\n",
    "\n",
    "# Set a tighter range with some padding (e.g., use 5th and 95th percentile or actual min/max)\n",
    "uplift_range = max(abs(uplift_min), abs(uplift_max))\n",
    "# Round to nearest 5% for cleaner visualization\n",
    "uplift_range = np.ceil(uplift_range / 5) * 5\n",
    "\n",
    "fig_uplift_peak = px.choropleth_mapbox(\n",
    "    zones_temp_peak_merged,\n",
    "    geojson=zones_temp_peak_merged.geometry.__geo_interface__,\n",
    "    locations=zones_temp_peak_merged.index,\n",
    "    color=\"pct_uplift_cold_vs_notcold\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    center={\"lat\": 40.75, \"lon\": -73.97},\n",
    "    zoom=9.7,\n",
    "    opacity=0.85,\n",
    "    color_continuous_scale=\"RdBu_r\",  \n",
    "    range_color=[-uplift_range, uplift_range],  \n",
    "    title=\"Heatmap: Percentage Uplift in Demand — COLD vs Not Cold (PM Peak)\"\n",
    ")\n",
    "fig_uplift_peak.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig_uplift_peak.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e60b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "\n",
    "pm_peak_hours = [17, 18]  # 5–7 PM\n",
    "\n",
    "median_temp = combined_df.approxQuantile(\"temperature_c\", [0.5], 0.001)[0]\n",
    "\n",
    "combined_df_peak = (\n",
    "    combined_df\n",
    "    .withColumn(\"temp_bin\",\n",
    "        F.when(F.col(\"temperature_c\") <= median_temp, \"Colder 50%\")\n",
    "         .otherwise(\"Warmer 50%\")\n",
    "    )\n",
    "    .withColumn(\"hour\", F.hour(\"pickup_hour\"))\n",
    "    .filter(F.col(\"hour\").isin(pm_peak_hours))\n",
    ")\n",
    "zone_temp = combined_df_peak.groupBy(\"PULocationID\", \"temp_bin\").agg(\n",
    "    F.count(\"*\").alias(\"total_trips\"),\n",
    "    F.countDistinct(\"pickup_hour\").alias(\"num_hours\")\n",
    ")\n",
    "\n",
    "zone_temp = zone_temp.withColumn(\n",
    "    \"avg_trips\",\n",
    "    F.when(F.col(\"num_hours\") > 0, F.col(\"total_trips\") / F.col(\"num_hours\")).otherwise(0)\n",
    ")\n",
    "\n",
    "zone_temp_pivot = (\n",
    "    zone_temp.groupBy(\"PULocationID\")\n",
    "             .pivot(\"temp_bin\", [\"Colder 50%\", \"Warmer 50%\"])\n",
    "             .agg(F.first(\"avg_trips\"))\n",
    "             .fillna(0)\n",
    ")\n",
    "\n",
    "zone_temp_pd = zone_temp_pivot.toPandas()\n",
    "\n",
    "zone_temp_pd[\"pct_uplift_cold_vs_warm\"] = np.where(\n",
    "    zone_temp_pd[\"Warmer 50%\"] > 0,\n",
    "    (zone_temp_pd[\"Colder 50%\"] - zone_temp_pd[\"Warmer 50%\"]) / zone_temp_pd[\"Warmer 50%\"] * 100,\n",
    "    0\n",
    ")\n",
    "\n",
    "# Log scaling for clarity\n",
    "zone_temp_pd[\"log_cold\"] = np.log1p(zone_temp_pd[\"Colder 50%\"])\n",
    "zone_temp_pd[\"log_warm\"] = np.log1p(zone_temp_pd[\"Warmer 50%\"])\n",
    "\n",
    "zones_geo = gpd.read_file(\"taxi_zones.geojson\")\n",
    "zones_geo[\"location_id\"] = zones_geo[\"location_id\"].astype(int)\n",
    "\n",
    "zones_temp_merged = zones_geo.merge(\n",
    "    zone_temp_pd, left_on=\"location_id\", right_on=\"PULocationID\", how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "# Shared color scale\n",
    "custom_scale = [\"blue\",\"green\",\"yellow\",\"orange\",\"red\"]\n",
    "\n",
    "# =======================\n",
    "# HEATMAP — Colder 50%\n",
    "# =======================\n",
    "fig_cold = px.choropleth_mapbox(\n",
    "    zones_temp_merged,\n",
    "    geojson=zones_temp_merged.geometry.__geo_interface__,\n",
    "    locations=zones_temp_merged.index,\n",
    "    color=\"log_cold\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    center={\"lat\": 40.75, \"lon\": -73.97},\n",
    "    zoom=9.7,\n",
    "    opacity=0.85,\n",
    "    color_continuous_scale=custom_scale,\n",
    "    title=\"Heatmap: PM Peak Taxi Pickups — Coldest 50% Temperatures\"\n",
    ")\n",
    "fig_cold.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig_cold.show()\n",
    "\n",
    "fig_warm = px.choropleth_mapbox(\n",
    "    zones_temp_merged,\n",
    "    geojson=zones_temp_merged.geometry.__geo_interface__,\n",
    "    locations=zones_temp_merged.index,\n",
    "    color=\"log_warm\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    center={\"lat\": 40.75, \"lon\": -73.97},\n",
    "    zoom=9.7,\n",
    "    opacity=0.85,\n",
    "    color_continuous_scale=custom_scale,\n",
    "    title=\"Heatmap: PM Peak Taxi Pickups — Warmest 50% Temperatures\"\n",
    ")\n",
    "fig_warm.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig_warm.show()\n",
    "\n",
    "fig_uplift = px.choropleth_mapbox(\n",
    "    zones_temp_merged,\n",
    "    geojson=zones_temp_merged.geometry.__geo_interface__,\n",
    "    locations=zones_temp_merged.index,\n",
    "    color=\"pct_uplift_cold_vs_warm\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    center={\"lat\": 40.75, \"lon\": -73.97},\n",
    "    zoom=9.7,\n",
    "    opacity=0.85,\n",
    "    color_continuous_scale=custom_scale,\n",
    "    title=\"Heatmap: % Uplift in Taxi Demand — Coldest vs Warmest 50% (PM Peak)\"\n",
    ")\n",
    "fig_uplift.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig_uplift.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2c966f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b112b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparkenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
